/**
 * Optimized Mermaid diagram templates
 * Clean, simple flowcharts without subgraphs for better rendering
 */

export const MERMAID_DIAGRAMS: Record<string, { architecture: string; workflow: string }> = {
  'social-media-sentiment': {
    architecture: `graph LR
      A[üì± Social Apps] -->|Stream| B[üì® Kafka]
      B -->|Ingest| C[‚ö° Spark]
      C -->|Process| D[üß† BERT]
      D -->|Store| E[üíæ Features]
      D -->|Alert| F[üîî Alerts]
      F -->|Send| G[üìä Dashboard]
      E -->|Feedback| C`,
    workflow: `graph TD
      A[üì• Raw Stream] --> B[üåê Lang Detect]
      B --> C[üìù Tokenize]
      C --> D[üß† BERT]
      D --> E[üìä Aggregate]
      E --> F[üö® Alerts]
      F --> G[üìà Dashboard]`
  },
  
  'customer-churn-intelligence': {
    architecture: `graph LR
      A[üóÑÔ∏è Data Lake] --> B[üîÑ Airflow]
      B --> C[üì¶ Features]
      C --> D[üß™ MLflow]
      D --> E[ü§ñ Ensemble]
      E --> F[‚öôÔ∏è FastAPI]
      F --> G[üìä Dashboard]
      G -->|Feedback| B`,
    workflow: `graph TD
      A[üì• Ingest] --> B[üßπ Clean]
      B --> C[üìö Train]
      C --> D[‚úÖ Register]
      D --> E[üöÄ Deploy]
      E --> F[üì° Monitor]
      F -->|Retrain| A`
  },
  
  'brain-tumor-classification': {
    architecture: `graph LR
      A[üè• PACS] --> B[üñºÔ∏è Preprocess]
      B --> C[üß† CNN]
      C --> D[üîç Grad-CAM]
      D --> E[üìã Report]
      E --> F[üë®‚Äç‚öïÔ∏è Portal]`,
    workflow: `graph TD
      A[üì§ MRI Input] --> B[‚öôÔ∏è Normalize]
      B --> C[üß† CNN]
      C --> D[üî• Heatmap]
      D --> E[‚úîÔ∏è QA Review]
      E --> F[üìÑ Export]`
  },
  
  'financial-fraud-detection': {
    architecture: `graph LR
      A[üí≥ Payments] --> B[üì® Kafka]
      B --> C[üî¢ Features]
      C --> D[ü§ñ Autoencoder]
      C --> E[üå≥ IsoForest]
      D --> F[‚ö° Scorer]
      E --> F
      F --> G[üö® SOC]`,
    workflow: `graph TD
      A[üí∏ Transaction] --> B[‚öôÔ∏è Normalize]
      B --> C[üìä Encode]
      C --> D[üéØ Threshold]
      D --> E[üìã Case]
      E --> F[üëÅÔ∏è Review]`
  },
  
  'yolov8-inference-engine': {
    architecture: `graph LR
      A[üìπ Cameras] --> B[üîÑ Preprocess]
      B --> C[üéØ YOLOv8]
      C --> D[‚ö° TensorRT]
      D --> E[üåê Gateway]
      E --> F[üìä Monitor]`,
    workflow: `graph TD
      A[üìπ Frame] --> B[üîÄ Decode]
      B --> C[üñºÔ∏è Resize]
      C --> D[üéØ Detect]
      D --> E[üßπ NMS]
      E --> F[‚úèÔ∏è Annotate]
      F --> G[üì§ Stream]`
  },
  
  'hybrid-recommendation-engine': {
    architecture: `graph LR
      A[üë§ Events] --> B[üíæ Features]
      B --> C[üß† Embeddings]
      C --> D[‚ö° FAISS]
      D --> E[üéØ Candidates]
      E --> F[üìä Ranker]
      F --> G[üéÅ Diversify]
      G --> H[üöÄ API]`,
    workflow: `graph TD
      A[üë§ Signals] --> B[üì¶ Embed]
      B --> C[üîç Search]
      C --> D[üîÑ Rerank]
      D --> E[üéØ Diversify]
      E --> F[üì§ Serve]
      F -->|Feedback| A`
  },
  
  'demand-forecasting-pipeline': {
    architecture: `graph LR
      A[üè™ Retail Data] --> B[‚ö° PySpark]
      B --> C[üì¶ Features]
      C --> D[üìà Prophet]
      C --> E[üå≥ XGBoost]
      D --> F[üéØ Ensemble]
      E --> F
      F --> G[üìä Dashboard]`,
    workflow: `graph TD
      A[üì• Sales] --> B[üßπ Clean]
      B --> C[‚öôÔ∏è Features]
      C --> D[üìö Prophet]
      C --> E[üìö XGBoost]
      D --> F[üìä Ensemble]
      E --> F
      F --> G[‚úîÔ∏è Validate]
      G --> H[üìà Publish]`
  },
  
  'resume-parser': {
    architecture: `graph LR
      A[üìÑ Upload] --> B[üßπ OCR]
      B --> C[üè∑Ô∏è NER]
      C --> D[üíº Skills]
      D --> E[üîç Match]
      E --> F[üë• Dashboard]`,
    workflow: `graph TD
      A[üì• Resume] --> B[üì§ OCR]
      B --> C[üßπ Clean]
      C --> D[üè∑Ô∏è Extract]
      D --> E[üéØ Normalize]
      E --> F[üîó Match]
      F --> G[üìä Score]`
  },
  
  'cloud-data-warehouse': {
    architecture: `graph LR
      A[üìä Sources] --> B[üåä Lake]
      B --> C[‚öôÔ∏è dbt]
      C --> D[üè¢ DW]
      D --> E[üìà BI]
      E --> F[üë• Users]`,
    workflow: `graph TD
      A[üîå Connect] --> B[üì• Extract]
      B --> C[üåä Stage]
      C --> D[‚öôÔ∏è Transform]
      D --> E[üóÑÔ∏è Load]
      E --> F[üîç Quality]
      F --> G[üìä Serve]`
  },
  
  'quantum-blood-group': {
    architecture: `graph LR
      A[ü©∏ Sample] --> B[üîÑ Preprocess]
      B --> C[üß† CNN]
      C --> D[‚öõÔ∏è VQC]
      D --> E[üéØ Classify]
      E --> F[üìä Results]`,
    workflow: `graph TD
      A[üì∏ Image] --> B[‚öôÔ∏è Normalize]
      B --> C[üß† Features]
      C --> D[‚öõÔ∏è Quantum]
      D --> E[üìä Output]
      E --> F[‚úîÔ∏è Classify]`
  }
};
